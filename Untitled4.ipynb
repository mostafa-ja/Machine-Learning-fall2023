{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Machine-Learning-fall2023/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Questions"
      ],
      "metadata": {
        "id": "1xDv7Luc5fw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps to Build an Image Classification Model using CNN"
      ],
      "metadata": {
        "id": "EcsYA8FS119I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we train a CNN model, let’s build a basic, Fully Connected Neural Network for the dataset. The basic steps to build an image classification model using a neural network are:\n",
        "\n",
        "1. Flatten the input image dimensions to 1D (width pixels x height pixels)\n",
        "2. Normalize the image pixel values (divide by 255)\n",
        "3. One-Hot Encode the categorical column\n",
        "4. Build a model architecture (Sequential) with Dense layers(Fully connected layers)\n",
        "5. Train the model and make predictions\n",
        "\n",
        "Here’s how you can build a neural network model for MNIST. I have used relu and softmax as the activation function and adam optimizer, with accuracy being the evaluation metrics. The code contains all the steps from data loading to preprocessing to fitting the model. I have commented on the relevant parts of the code for better understanding:"
      ],
      "metadata": {
        "id": "kI77A2M92ANe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
        "from keras.utils import to_categorical\n",
        "#from keras.utils import np_utils\n"
      ],
      "metadata": {
        "id": "yovPUtV22WNW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Flattening the images from the 28x28 pixels to 1D 787 pixels\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalizing the data to help with the training\n",
        "X_train /= 255.\n",
        "X_test /= 255.\n",
        "\n",
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = to_categorical(y_train, n_classes)\n",
        "Y_test = to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)\n"
      ],
      "metadata": {
        "id": "QcRo7d-J1__P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c078a322-f39f-450c-e82c-e1add6422b43"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Shape before one-hot encoding:  (60000,)\n",
            "Shape after one-hot encoding:  (60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ne6Y8K9q11Zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c0f80e-f3df-4958-db02-844d7536fcfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 2s 6ms/step - loss: 0.4667 - accuracy: 0.8749 - val_loss: 0.2462 - val_accuracy: 0.9313\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2192 - accuracy: 0.9385 - val_loss: 0.1919 - val_accuracy: 0.9446\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1667 - accuracy: 0.9521 - val_loss: 0.1537 - val_accuracy: 0.9553\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1344 - accuracy: 0.9617 - val_loss: 0.1283 - val_accuracy: 0.9618\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1133 - accuracy: 0.9675 - val_loss: 0.1179 - val_accuracy: 0.9651\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0958 - accuracy: 0.9723 - val_loss: 0.1046 - val_accuracy: 0.9692\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0836 - accuracy: 0.9762 - val_loss: 0.0985 - val_accuracy: 0.9691\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0734 - accuracy: 0.9796 - val_loss: 0.0920 - val_accuracy: 0.9724\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9821 - val_loss: 0.0870 - val_accuracy: 0.9742\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0580 - accuracy: 0.9840 - val_loss: 0.0814 - val_accuracy: 0.9747\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0516 - accuracy: 0.9859 - val_loss: 0.0801 - val_accuracy: 0.9753\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0466 - accuracy: 0.9876 - val_loss: 0.0757 - val_accuracy: 0.9776\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0419 - accuracy: 0.9887 - val_loss: 0.0763 - val_accuracy: 0.9772\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0372 - accuracy: 0.9905 - val_loss: 0.0796 - val_accuracy: 0.9766\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.0742 - val_accuracy: 0.9764\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0301 - accuracy: 0.9924 - val_loss: 0.0749 - val_accuracy: 0.9769\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0271 - accuracy: 0.9936 - val_loss: 0.0744 - val_accuracy: 0.9767\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0243 - accuracy: 0.9944 - val_loss: 0.0757 - val_accuracy: 0.9777\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0223 - accuracy: 0.9947 - val_loss: 0.0740 - val_accuracy: 0.9773\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0199 - accuracy: 0.9956 - val_loss: 0.0707 - val_accuracy: 0.9793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c1615c0b550>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# hidden layer\n",
        "\n",
        "model.add(Dense(100, input_shape=(784,), activation='relu'))\n",
        "\n",
        "# output layer\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# looking at the model summary\n",
        "model.summary()\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "\n",
        "# training the model for 10 epochs (use model.fit function)\n",
        "model.fit(X_train, Y_train, batch_size=256, epochs=20, validation_data=(X_test, Y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the above code, you’d realized that we are getting a good validation accuracy of around 97% easily.\n",
        "\n",
        "One major advantage of using ConvNets over NNs is that you do not need to flatten the input images to 1D as they are capable of working with image data in 2D. This helps in retaining the “spatial” properties of images."
      ],
      "metadata": {
        "id": "4ZA86kTT22-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Code for the CNN Model\n"
      ],
      "metadata": {
        "id": "KU9pJrK82_ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# to calculate accuracy\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "CC-6DWpR3GVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# building the input vector from the 28x28 pixels\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalizing the data to help with the training\n",
        "X_train /= 255.\n",
        "X_test /= 255.\n",
        "\n",
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "V4k7JpTd3ESt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# convolutional layer\n",
        "\n",
        "'''\n",
        "enter your code here\n",
        "\n",
        "'''\n",
        "\n",
        "# MaxPool layer\n",
        "\n",
        "'''\n",
        "enter your code here\n",
        "\n",
        "'''\n",
        "\n",
        "# flatten output of conv\n",
        "\n",
        "'''\n",
        "enter your code here\n",
        "\n",
        "'''\n",
        "\n",
        "# hidden layer\n",
        "\n",
        "'''\n",
        "enter your code here\n",
        "\n",
        "'''\n",
        "\n",
        "# output layer\n",
        "\n",
        "'''\n",
        "enter your code here\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# training the model for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "id": "JWj4yk1R3OG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though our max validation accuracy by using a simple neural network model was around 97%, the CNN model is able to get 98%+ with just a single convolution layer! :)"
      ],
      "metadata": {
        "id": "d9e7-OIL3nOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanatory Questions\n"
      ],
      "metadata": {
        "id": "v3e20ACH5aHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Q1. explain about each activation Functions used in Neural Networks and compare them:\n",
        "\n",
        "a.Sigmoid\n",
        "\n",
        "b.Tanh\n",
        "\n",
        "c.Relu"
      ],
      "metadata": {
        "id": "cn_AxHiH4Nvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. explain about Epoch, Batch, and Iteration in Neural Networks"
      ],
      "metadata": {
        "id": "Ezkbj4Wm4z1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3.  What is the difference between a convolutional neural network and a fully connected neural network?"
      ],
      "metadata": {
        "id": "v75tFc42462m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4.  What is the role of activation functions in neural networks?"
      ],
      "metadata": {
        "id": "ZNH2B76A5B_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5.  What is a dropout layer, and how is it used in neural networks?"
      ],
      "metadata": {
        "id": "1xK95Vy05Jmu"
      }
    }
  ]
}